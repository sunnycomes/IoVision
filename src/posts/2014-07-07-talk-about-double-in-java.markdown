---
title: "聊一聊Java中double精度去哪了(1)"
date: 2014-07-07 21:30:11
---
前段时间，因为要测试一个刚出炉的高频策略，放实盘去跑吧，怕出岔，所以写了个简单的回测系统，跑一遍历史数据。其中有一部分是关于撮合系统，简陋了点，还算能跑得起来，几个用例下来，也没什么问题，接着增加历史数据量，居然出现了负数，简直不可能发生的事情居然出现了，虽然都是小金额的偏差，但是毕竟跟钱打交道，必须谨慎，况且现在比特币那么贵，丝毫偏差都是不允许的！

当然，后面就是苦逼的找bug，逻辑没问题，发狠的，把所有的数据都打印出来，日志一页一页没有尽头，心里发麻，硬着头皮一条条排查，人品不错，开头就发现一条异常数据，0.05+0.01＝0.060000000000000005，瞬间明白，google it，才发现Java的double原来精度那么蛋疼。网上推荐BigDecimal代替double，果然不错，那就用BigDecimal替换。等所有的double都换之后，狗血的事情发生了，BigDecimal是如此的慢，以至于跑一个用例花了之前N倍的时间，怎么办，只能用一个折中的办法，数值表示仍然用double，数值计算用BigDecimal，于是乎，有了如下的一个四则运算工具类MathUtil.java

<!-- more -->

<script src="https://gist.github.com/sunnycomes/294abb067fbd662c60f5.js"></script>

当然，这里我想做的，不仅仅只是找到解决方案，更多的事想理解为什么double会出现这样的问题，如果是其他语言，例如C，会不会也出现这样的问题，我试着用同一组数据，发现C对于这组数据是没有出现异常的，那么，Java为什么会这么与众不同呢？

网上说其他语言也有类似的情况，那么我们该如何避免这些地雷呢？

既然Java的double问题那么多，我当前系统用double表示数值，会不会出现偏差？

如果Java中采用BigDecimal效率这么低，那些大型交易所，性能要求极高，如何控制延迟呢？或者还有其他更好的技术？

各种疑问在脑中盘旋，打破沙锅问到底的瘾又翻了，后面将追加博文，彻底研究下，Java的double精度去哪了。



